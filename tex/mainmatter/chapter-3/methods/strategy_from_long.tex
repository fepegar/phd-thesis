\subsubsection{Leveraging unlabeled data from the target domain}
\label{sec:leveraging_semi}

Let $D\unl = \{ \X_{\text{postop}_i} \}_{i = 1}^{n\st{unl}}$ be a dataset comprising $n\st{unl}$ unlabeled postoperative images.
We propose to leverage $D\unl$ to build a better predictive model than using simulated resections only, employing a semi-supervised learning approach.
First, pseudolabels for each image $\X\post \in D\unl$ can be generated with $f_{\theta_{\text{sim}}}$ using data distillation, i.e., ensembling multiple predictions from transformed versions of $\X\post$.
Using the multiple predictions generated for pseudolabels, we estimate image-level segmentation uncertainty so that only instances with high reliability are used for training.
Finally, simulated resection instances and the selected pseudolabeled instances are used to train a new model $f_{\theta_{\text{sim+unl}}}$ in a hybrid self- and semi-supervised setting.


\paragraph{Generating pseudolabels using data distillation}

Data distillation is a method that ensembles predictions from multiple transformations applied to data, using a single model \cite{radosavovic_data_2017}.
We use Monte Carlo simulation to generate each pseudolabel with \ac{TTA}, which can improve the performance of segmentation models \cite{wang_aleatoric_2019}.
Let $n\st{u}$ represent the total number of simulation runs.
In the $i$-th simulation run,
the \ac{TTA} intensity and spatial transforms $T_\alpha$ and $T_\beta$ (\cref{sec:preprocessing_augmentation}) are applied to $\X\post$.
$\fp{sim}$ is used to predict $\wt{\Y}_{\theta\alpha\beta}'$, the probability of each voxel belonging to the cavity in the transformed space.
Finally, $T_\beta^{-1}$ is used to transform $\wt{\Y}_{\theta\alpha\beta}'$ back onto the space of $\X\post$:
\begin{equation}
    \wt{\Y}'_{\text{cavity}_i}
    = T_\beta^{-1}
    \circ \fp{sim}
    \circ T_\beta
    \circ T_\alpha
    \circ \X\post
    = T_\beta^{-1} \left( \wt{\Y}_{\theta\alpha\beta}' \right)
\end{equation}

We ensure that $T_\beta$ is invertible by using diffeomorphic spatial transformations.
To preserve image quality and ensure that probabilities stay within $[0, 1]$, we use tricubic and trilinear interpolation for $T_\beta$ and $T_\beta^{-1}$, respectively.

Predictions $P = \{ \wt{\Y}'_{\text{cavity}_i} \}_{i=1}^{n\st{u}}$ are averaged to obtain $\img{\wt{\Y}\cav}{[0, 1]}$, and the corresponding binary pseudolabel $\binimg{\widetilde{\Y}\cav}$ is obtained applying a threshold of 0.5 to $\wt{\Y}'\cav$.


\paragraph{Uncertainty estimation as selection criterion for pseudolabeled instances}

Images in $D\unl$ might have artifacts that limit the quality of the segmentation or include resection cavities not modeled by $\phi\simul$.
The corresponding noisy pseudolabels would hinder training of machine learning models.

As $n\st{unl}$ might be large, rather than performing manual quality control to select pseudolabels with high reliability for training, we use uncertainty estimation as an automated selection criterion \cite{venturini_uncertainty_2020}.

We use $n\st{unc}$ \ac{TTA} predictions to estimate aleatoric uncertainty, which captures noise inherent in the observation \cite{kendall_what_2017}.
Aleatoric uncertainty can indicate segmentation quality and is a successful selection criterion of pseudolabels in semi-supervised learning settings for medical image segmentation \cite{wang_aleatoric_2019,venturini_uncertainty_2020}.

Let $L = \{ l_i \}_{i = 1}^{n\st{unc}}$ denote the set of (soft) volumes of the segmented cavity for each prediction, where $l_i$ is the sum of all probabilities in the $i$-th prediction $\wt{\Y}'_{\text{cavity}_i} \in P$.
We use the \ac{CQV} of the volumes \cite{zwillinger_crc_1999,wang_aleatoric_2019} to estimate the image-level uncertainty $u : L \to \left[0, 1\right]$:
\begin{equation}
    u = \frac{q_3 - q_1}{q_3 + q_1}
\end{equation}
where $q_1$ and $q_3$ are the first and third quartiles of $L$, respectively.
The \ac{CQV} is agnostic to the volume of the segmented resection cavity and therefore avoids bias introduced by naturally-occurring uncertainty along the resection boundaries \cite{jungo_analyzing_2020}.
Finally, training instances with an associated prediction uncertainty $u(f_{\theta\alpha\beta}, \X\post, n\st{unc})$ below a threshold $t\st{unc}$ are combined with self-labeled instances (\cref{sec:sim_res_self}) to train a new model.
