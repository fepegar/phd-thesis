\subsubsection{Deep learning frameworks}
\label{sec:frameworks}

There are currently two major generic deep learning frameworks: TensorFlow \cite{abadi_tensorflow_2016} and PyTorch \cite{paszke_pytorch_2019}, primarily maintained by Google and Facebook, respectively.
Although TensorFlow has traditionally been the primary choice for both research and industry, PyTorch has recently seen a substantial increase in popularity, especially among the research community \cite{he_state_2019}.

PyTorch is often preferred by the research community as it is \textit{pythonic}, i.e., its design, usage, and \ac{API} follow the conventions of plain Python. Moreover, the \ac{API} for tensor operations follows a similar paradigm to the one for NumPy multidimensional arrays, which is the primary array programming library for the Python language \cite{van_der_walt_numpy_2011}.
In contrast, for TensorFlow, researchers need to become familiar with new design elements such as sessions, placeholders, feed dictionaries, gradient tapes and static graphs.
In PyTorch, objects are standard Python classes and variables, and a dynamic graph makes debugging intuitive and familiar to anyone already using Python.
These differences have decreased with the recent release of TensorFlow 2, whose eager mode makes usage reminiscent of Python.

TorchIO was designed to be in the style of PyTorch and uses several of its tools to reduce the barrier to learning how to use TorchIO for those researchers already familiar with PyTorch.
