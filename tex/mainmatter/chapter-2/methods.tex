\subsection{Snippet-level classification}
\label{sec:snippet-level}

The probability $\hat{Y}_k$ that a patient presents generalizing features within snippet $\x_k$ starting at frame $k$ is computed as
\begin{equation}
    \Ypred_k = \Pr(Y_k = 1 \mid \x_k) = \Fzx( \Cx(\x_k) ) = \Fzx( \z_k)
\end{equation}
where
$\Cx$ is an \ac{STCNN} parameterized by $\pars{\x}$ that extracts features,
$\z_k \in \R ^ m$ is a vector of $m$ features representing $\x_k$ in a latent space,
and
$\Fzx$ is a fully-connected layer parameterized by $\pars{\z,\x}$ followed by a sigmoid function that maps logits to probabilities.
In this work, we do not update $\pars{\x}$ during training.


\subsection{Seizure-level classification}
\label{sec:meth_seizure}

\subsubsection{Temporal segment network}
Let $V = \{ \x_k \}_{k=1}^{K-l}$ be the set of all possible snippets sampled from a seizure video.
We define a sampling function $f : (V, n, \gamma) \mapsto S$ that extracts a sequence $S$ of $n$ snippets by splitting $V$ into $n$ non-overlapping segments and randomly sampling one snippet per segment.
There are two design choices: the number of segments $n$ and the probability distribution used for sampling within a segment.
If a uniform distribution is used,
information from two adjacent segments might be redundant.
Using the middle snippet of a segment minimizes redundancy, but reduces the proportion of data leveraged during training.
We propose using a symmetric beta distribution ($\text{Beta}(\gamma, \gamma)$) to model the sampling function,
where $\gamma$ controls the dispersion of the probability distribution (\cref{fig:betas}).
The set of latent snippet representations is $Z = \{ \Cx (\x_i) \}_{i = 1}^{n}$.


\subsubsection{Recurrent neural network}

To perform a seizure-level prediction $\hat{\Yb}$, $Z$ is aggregated as follows:
\begin{equation}
    \hat{\Yb}
    = \Pr(\Yb = 1 \mid S)
    = \Fzs( \Rs ( Z ) )
    = \Fzs( \z )
\end{equation}
where
$\Rs$ is an \ac{RNN} parameterized by $\pars{\sss}$,
$\Fzs$ is a fully-connected layer parameterized by $\pars{\z,\sss}$ which uses a softmax function to output probabilities,
and $\z$ is a feature-vector representation of the entire seizure video, corresponding to the last hidden state of $\Rs$.
